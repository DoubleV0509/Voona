{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea011f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/484pjr2d447dw2s8fwtrhw440000gn/T/ipykernel_24250/3212743309.py:50: MatplotlibDeprecationWarning:\n",
      "\n",
      "The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imort main libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # for photing and viewing data\n",
    "import matplotlib.pyplot as plt# plotting library\n",
    "import plotly.express as px\n",
    "import yfinance as yf\n",
    "# import the TrendReq method from the pytrends request module\n",
    "from pytrends.request import TrendReq\n",
    "from sklearn.datasets import make_blobs\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "# Import VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# import tensorflow and keras\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# Feature Selection using RFE\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from boruta import BorutaPy\n",
    "# Import SHAP\n",
    "import pandas_ta as ta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True, theme='pearl')\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from talib import MA_Type\n",
    "# Preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit, cross_val_score, KFold, ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit, TimeSeriesSplit\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, SelectPercentile\n",
    "# scikit-learn modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import talib\n",
    "# tensorflow modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM,RNN\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "# plotting & outputs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "from pprint import pprint\n",
    "# Classifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, roc_curve, RocCurveDisplay, ConfusionMatrixDisplay,\n",
    "    accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, auc,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2749cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-07-27</th>\n",
       "      <td>12.50</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>12.460</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>29257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-30</th>\n",
       "      <td>14.43</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>14.180</td>\n",
       "      <td>14.990</td>\n",
       "      <td>14.990</td>\n",
       "      <td>5767200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-31</th>\n",
       "      <td>16.00</td>\n",
       "      <td>17.084999</td>\n",
       "      <td>15.105</td>\n",
       "      <td>16.070</td>\n",
       "      <td>16.070</td>\n",
       "      <td>4441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-01</th>\n",
       "      <td>16.49</td>\n",
       "      <td>16.625000</td>\n",
       "      <td>15.200</td>\n",
       "      <td>15.540</td>\n",
       "      <td>15.540</td>\n",
       "      <td>3063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-02</th>\n",
       "      <td>16.00</td>\n",
       "      <td>16.915001</td>\n",
       "      <td>15.990</td>\n",
       "      <td>16.525</td>\n",
       "      <td>16.525</td>\n",
       "      <td>1969400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open       High     Low   Close  Adj Close    Volume\n",
       "Date                                                             \n",
       "2007-07-27  12.50  14.320000  12.460  14.000     14.000  29257200\n",
       "2007-07-30  14.43  15.925000  14.180  14.990     14.990   5767200\n",
       "2007-07-31  16.00  17.084999  15.105  16.070     16.070   4441600\n",
       "2007-08-01  16.49  16.625000  15.200  15.540     15.540   3063600\n",
       "2007-08-02  16.00  16.915001  15.990  16.525     16.525   1969400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price = yf.download(tickers = 'LULU', start=\"2001-05-21\", end=\"2023-05-21\", interval='1d')\n",
    "df_price.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e2732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.9/multiprocessing/resource_tracker.py:96: UserWarning:\n",
      "\n",
      "resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "0it [00:00, ?it/s]Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n",
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_price.ta.strategy('All',timed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82197cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(df):\n",
    "    \n",
    "    #calculate the basic columne-price factors\n",
    "    df['O-C'] = df.Open - df_price.Close\n",
    "    df['H-L'] = df.High - df_price.Low\n",
    "    df['Log_Return'] = np.log(df['Adj Close']).diff().dropna()\n",
    "    \n",
    "    df['Momentum_2'] = talib.MOM(df['Adj Close'], timeperiod=2)\n",
    "    df['Momentum_3'] = talib.MOM(df['Adj Close'], timeperiod=3)\n",
    "    df['Momentum_10'] = talib.MOM(df['Adj Close'], timeperiod=10)\n",
    "    \n",
    "    \n",
    "    df['EMA_2'] = talib.EMA(df['Adj Close'], timeperiod=2)\n",
    "    df['EMA_2'] = talib.EMA(df['Adj Close'], timeperiod=3)\n",
    "    df['EMA_10'] = talib.EMA(df['Adj Close'], timeperiod=10)\n",
    "    \n",
    "    df['Lag_Return_2'] = df['Adj Close'].pct_change(periods=2)\n",
    "    df['Lag_Return_3'] = df['Adj Close'].pct_change(periods=3)\n",
    "    df['Lag_Return_10'] = df['Adj Close'].pct_change(periods=10)\n",
    "    \n",
    "    df['SMA_2'] = talib.SMA(df['Adj Close'], timeperiod=2)\n",
    "    df['SMA_3'] = talib.SMA(df['Adj Close'], timeperiod=3)\n",
    "    df['SMA_10'] = talib.SMA(df['Adj Close'], timeperiod=10)\n",
    "    \n",
    "\n",
    "    # Calculate Relative Strength Index (RSI)\n",
    "    df['RSI'] = talib.RSI(df['Adj Close'], timeperiod=14)  # 14-period Relative Strength Index\n",
    "\n",
    "    # Calculate Moving Average Convergence Divergence (MACD)\n",
    "    macd, macdsignal, macdhist = talib.MACD(df['Adj Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['MACD'] = macd\n",
    "    df['MACD_signal'] = macdsignal\n",
    "    df['MACD_hist'] = macdhist\n",
    "\n",
    "    # Calculate Bollinger Bands (BBANDS)\n",
    "    upper, middle, lower = talib.BBANDS(df['Adj Close'], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "    df['BBANDS_upper'] = upper\n",
    "    df['BBANDS_middle'] = middle\n",
    "    df['BBANDS_lower'] = lower\n",
    "\n",
    "    # Calculate Average True Range (ATR)\n",
    "    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Adj Close'], timeperiod=14)  # 14-period Average True Range\n",
    "\n",
    "    # Calculate Stochastic Oscillator\n",
    "    slowk, slowd = talib.STOCH(df['High'], df['Low'], df['Adj Close'], fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "    df['Stoch_slowk'] = slowk\n",
    "    df['Stoch_slowd'] = slowd\n",
    "\n",
    "    # Calculate Average Directional Movement Index (ADX)\n",
    "    df['ADX'] = talib.ADX(df['High'], df['Low'], df['Adj Close'], timeperiod=14)  # 14-period Average Directional Movement Index\n",
    "\n",
    "    # Calculate Chaikin Oscillator\n",
    "    df['Chaikin'] = talib.ADOSC(df['High'], df['Low'], df['Close'], df['Volume'], fastperiod=3, slowperiod=10)  # 3/10-period Chaikin Oscillator\n",
    "\n",
    "    # Calculate On Balance Volume (OBV)\n",
    "    df['OBV'] = talib.OBV(df['Close'], df['Volume'])\n",
    "\n",
    "    # Calculate Average Directional Index (ADI)\n",
    "    df['ADI'] = talib.AD(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "\n",
    "    # Calculate Commodity Channel Index (CCI)\n",
    "    df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=20)  # 20-period Commodity Channel Index\n",
    "\n",
    "    # Calculate Rate of Change (ROC)\n",
    "    df['ROC'] = talib.ROC(df['Close'], timeperiod=10)  # 10-period Rate of Change\n",
    "\n",
    "    # Calculate Money Flow Index (MFI)\n",
    "    df['MFI'] = talib.MFI(df['High'], df['Low'], df['Close'], df['Volume'], timeperiod=14)  # 14-period Money Flow Index\n",
    "\n",
    "    # Calculate Williams %R (WILLR)\n",
    "    df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)  # 14-period Williams %R\n",
    "\n",
    "\n",
    "    # Calculate Parabolic SAR (SAR)\n",
    "    df['SAR'] = talib.SAR(df['High'], df['Low'], acceleration=0.02, maximum=0.2)\n",
    "\n",
    "    # Calculate Trix (TRIX)\n",
    "    df['TRIX'] = talib.TRIX(df['Close'], timeperiod=14)  # 14-period Trix\n",
    "\n",
    "    # Calculate Ultimate Oscillator (ULTOSC)\n",
    "    df['ULTOSC'] = talib.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)  # Ultimate Oscillator with periods 7, 14, and 28\n",
    "\n",
    "    # Calculate Aroon Oscillator (AROONOSC)\n",
    "    df['AROONOSC'] = talib.AROONOSC(df['High'], df['Low'], timeperiod=14)  # 14-period Aroon Oscillator\n",
    "        # Add more technical indicators as needed\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d614b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price = df_price.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = calculate_technical_indicators(df_price)\n",
    "df_price=pd.DataFrame(indicators)\n",
    "df_price=df_price.reset_index()\n",
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "\n",
    "# 设置起始和结束日期\n",
    "start_date = '2001-01-01'\n",
    "end_date = '2023-07-15'\n",
    "\n",
    "# 使用pandas_datareader获取Fama-French五因子模型数据\n",
    "ff_data = web.DataReader('F-F_Research_Data_5_Factors_2x3_daily', 'famafrench', start_date, end_date)\n",
    "mom_data = web.DataReader('F-F_Momentum_Factor_daily', 'famafrench', start_date, end_date)\n",
    "\n",
    "# 提取因子数据\n",
    "ff_factors = ff_data[0]\n",
    "mom_factor = mom_data[0]\n",
    "ff_factors=pd.concat([ff_factors, mom_factor], axis=1)\n",
    "ff_factors=ff_factors.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f509e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "ek.set_app_key('e6749e154a70460f9886340bcda525e945f42b8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df, err = ek.get_data(['LULU.O'], \n",
    "                      ['TR.Revenue.date','TR.Revenue','TR.GrossProfit'],\n",
    "                      {'Scale': 6, 'SDate': 0, 'EDate': -100, 'FRQ': 'FQ'})\n",
    "df['Date']=pd.to_datetime(df['Date']).dt.year\n",
    "df=df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da57344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, err = ek.get_data(['LULU.O'], \n",
    "                      [\"TR.TRESGScore.Date\",\"TR.TRESGScore\",\"TR.EnvironmentPillarScore\",'TR.SocialPillarScore','TR.GovernancePillarScore'],\n",
    "                      {'SDate':'0', 'EDate':'-19','Period':'FY0','Frq':'FY'})\n",
    "df1['Date']=pd.to_datetime(df1['Date']).dt.year\n",
    "df1=df1.dropna()\n",
    "df = df.merge(df1.drop('Instrument', axis=1), on='Date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=pd.to_datetime(df['Date'], format='%Y')\n",
    "df=df.set_index('Date').resample('D').bfill().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "upm=pd.read_excel('/Users/voona/Desktop/Conference/paper3/US_Policy_Uncertainty_Data.xlsx')\n",
    "upm=upm.drop(upm.index[-1])\n",
    "upm['Year']=upm['Year'].astype(int)\n",
    "upm['Month']=upm['Month'].astype(int)\n",
    "upm=upm[upm['Year']>2010]\n",
    "upm['Date'] = upm['Year'].astype(str) + '-' + upm['Month'].astype(str)\n",
    "upm=upm.drop(['Year','Month'],axis=1)\n",
    "upm['Date']=pd.to_datetime(upm['Date'],format=\"%Y-%m\")\n",
    "upm=upm.set_index('Date').resample('D').bfill().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(upm,on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429de0a7",
   "metadata": {},
   "source": [
    "## Machine Learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0811c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the TrendReq method by passing the host language (hl) and timezone (tz) parameters\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "# build list of keywords\n",
    "kw_list = [\"lululemon\"] \n",
    "\n",
    "# build the payload\n",
    "pytrends.build_payload(kw_list, timeframe='2011-01-01 2022-01-01', geo='US')\n",
    "df_google = pytrends.interest_over_time().reset_index()\n",
    "df_google=df_google.rename(columns={'date':\"Date\",'lululemon':\"GoogleIndex\"})\n",
    "df_google=df_google.set_index('Date').resample('D').bfill().reset_index()\n",
    "df_google=df_google.drop('isPartial', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fc48683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GoogleIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4019 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  GoogleIndex\n",
       "0    2011-01-01           13\n",
       "1    2011-01-02           12\n",
       "2    2011-01-03           12\n",
       "3    2011-01-04           12\n",
       "4    2011-01-05           12\n",
       "...         ...          ...\n",
       "4014 2021-12-28           81\n",
       "4015 2021-12-29           81\n",
       "4016 2021-12-30           81\n",
       "4017 2021-12-31           81\n",
       "4018 2022-01-01           81\n",
       "\n",
       "[4019 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d10bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(df_google,on='Date')\n",
    "df=df.merge(df_price,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4d51c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(ff_factors,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d6633e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Features= df.drop(['Open', 'High', 'Low', 'Close', 'Instrument',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "955763b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Revenue', 'Gross Profit', 'ESG Score',\n",
       "       'Environmental Pillar Score', 'Social Pillar Score',\n",
       "       'Governance Pillar Score', 'Three_Component_Index',\n",
       "       'News_Based_Policy_Uncert_Index', 'GoogleIndex', 'Adj Close', 'Volume',\n",
       "       'O-C', 'H-L', 'Log_Return', 'Momentum_2', 'Momentum_3', 'Momentum_10',\n",
       "       'EMA_2', 'EMA_10', 'Lag_Return_2', 'Lag_Return_3', 'Lag_Return_10',\n",
       "       'SMA_2', 'SMA_3', 'SMA_10', 'RSI', 'MACD', 'MACD_signal', 'MACD_hist',\n",
       "       'BBANDS_upper', 'BBANDS_middle', 'BBANDS_lower', 'ATR', 'Stoch_slowk',\n",
       "       'Stoch_slowd', 'ADX', 'Chaikin', 'OBV', 'ADI', 'CCI', 'ROC', 'MFI',\n",
       "       'WILLR', 'SAR', 'TRIX', 'ULTOSC', 'AROONOSC', 'Pass_Returns_2',\n",
       "       'Pass_Returns_3', 'Pass_Returns_5', 'Momentum_5', 'SMA_5', 'EMA',\n",
       "       'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Mom   '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ce104e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Features.to_csv('/Users/voona/Desktop/考证/CQF exam/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac79913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2765 entries, 0 to 2764\n",
      "Data columns (total 55 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   Date                            2765 non-null   datetime64[ns]\n",
      " 1   Revenue                         2765 non-null   Float64       \n",
      " 2   Gross Profit                    2765 non-null   Float64       \n",
      " 3   ESG Score                       2765 non-null   Float64       \n",
      " 4   Environmental Pillar Score      2765 non-null   Float64       \n",
      " 5   Social Pillar Score             2765 non-null   Float64       \n",
      " 6   Governance Pillar Score         2765 non-null   Float64       \n",
      " 7   Three_Component_Index           2765 non-null   float64       \n",
      " 8   News_Based_Policy_Uncert_Index  2765 non-null   float64       \n",
      " 9   GoogleIndex                     2765 non-null   int64         \n",
      " 10  Adj Close                       2765 non-null   float64       \n",
      " 11  Volume                          2765 non-null   float64       \n",
      " 12  RSI                             2765 non-null   float64       \n",
      " 13  MACD                            2765 non-null   float64       \n",
      " 14  MACD_signal                     2765 non-null   float64       \n",
      " 15  MACD_hist                       2765 non-null   float64       \n",
      " 16  BBANDS_upper                    2765 non-null   float64       \n",
      " 17  BBANDS_middle                   2765 non-null   float64       \n",
      " 18  BBANDS_lower                    2765 non-null   float64       \n",
      " 19  ATR                             2765 non-null   float64       \n",
      " 20  Stoch_slowk                     2765 non-null   float64       \n",
      " 21  Stoch_slowd                     2765 non-null   float64       \n",
      " 22  ADX                             2765 non-null   float64       \n",
      " 23  Chaikin                         2765 non-null   float64       \n",
      " 24  OBV                             2765 non-null   float64       \n",
      " 25  ADI                             2765 non-null   float64       \n",
      " 26  CCI                             2765 non-null   float64       \n",
      " 27  ROC                             2765 non-null   float64       \n",
      " 28  MFI                             2765 non-null   float64       \n",
      " 29  WILLR                           2765 non-null   float64       \n",
      " 30  SAR                             2765 non-null   float64       \n",
      " 31  TRIX                            2765 non-null   float64       \n",
      " 32  ULTOSC                          2765 non-null   float64       \n",
      " 33  AROONOSC                        2765 non-null   float64       \n",
      " 34  O-C                             2765 non-null   float64       \n",
      " 35  H-L                             2765 non-null   float64       \n",
      " 36  Log_Return                      2765 non-null   float64       \n",
      " 37  Pass_Returns_2                  2765 non-null   float64       \n",
      " 38  Pass_Returns_3                  2765 non-null   float64       \n",
      " 39  Pass_Returns_5                  2765 non-null   float64       \n",
      " 40  Momentum_2                      2765 non-null   float64       \n",
      " 41  Momentum_3                      2765 non-null   float64       \n",
      " 42  Momentum_5                      2765 non-null   float64       \n",
      " 43  SMA_2                           2765 non-null   float64       \n",
      " 44  SMA_3                           2765 non-null   float64       \n",
      " 45  SMA_5                           2765 non-null   float64       \n",
      " 46  EMA                             2765 non-null   float64       \n",
      " 47  Mkt-RF                          2765 non-null   float64       \n",
      " 48  SMB                             2765 non-null   float64       \n",
      " 49  HML                             2765 non-null   float64       \n",
      " 50  RMW                             2765 non-null   float64       \n",
      " 51  CMA                             2765 non-null   float64       \n",
      " 52  RF                              2765 non-null   float64       \n",
      " 53  Mom                             2765 non-null   float64       \n",
      " 54  Sign                            2765 non-null   float64       \n",
      "dtypes: Float64(6), datetime64[ns](1), float64(47), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "#set the threshold for the extreme near zero value \n",
    "# To aviod the loss the potentional gains , we have to set the thrwshold as lower as possible.\n",
    "df_Features['Sign'] = np.where(df_Features['Log_Return']>0,1,0)\n",
    "df_Features['Sign'] = df_Features['Sign'].shift(-1)\n",
    "df_Features=df_Features.dropna()\n",
    "X = df_Features.loc[:,[\n",
    "       'News_Based_Policy_Uncert_Index', 'GoogleIndex', 'Adj Close', 'Volume',\n",
    "       'RSI', 'MACD', 'MACD_signal', 'MACD_hist', 'BBANDS_upper',\n",
    "       'BBANDS_middle', 'BBANDS_lower', 'ATR', 'Stoch_slowk', 'Stoch_slowd',\n",
    "       'ADX', 'Chaikin', 'OBV', 'ADI', 'CCI', 'ROC', 'MFI', 'WILLR', 'SAR',\n",
    "       'TRIX', 'ULTOSC', 'AROONOSC', 'O-C', 'H-L', 'Log_Return',\n",
    "       'Pass_Returns_2', 'Pass_Returns_3', 'Pass_Returns_5', 'Momentum_2',\n",
    "       'Momentum_3', 'Momentum_5', 'SMA_2', 'SMA_3', 'SMA_5', 'EMA', 'Mkt-RF',\n",
    "       'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Mom   ']]\n",
    "feature_names = X.columns\n",
    "y = df_Features['Sign']\n",
    "y = y.values\n",
    "# pandas-ta converts all dtype to objects\n",
    "y = y.astype(int) \n",
    "df_Features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85399d",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d7f43ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                              0\n",
       "Revenue                           0\n",
       "Gross Profit                      0\n",
       "ESG Score                         0\n",
       "Environmental Pillar Score        0\n",
       "Social Pillar Score               0\n",
       "Governance Pillar Score           0\n",
       "Three_Component_Index             0\n",
       "News_Based_Policy_Uncert_Index    0\n",
       "GoogleIndex                       0\n",
       "Adj Close                         0\n",
       "Volume                            0\n",
       "RSI                               0\n",
       "MACD                              0\n",
       "MACD_signal                       0\n",
       "MACD_hist                         0\n",
       "BBANDS_upper                      0\n",
       "BBANDS_middle                     0\n",
       "BBANDS_lower                      0\n",
       "ATR                               0\n",
       "Stoch_slowk                       0\n",
       "Stoch_slowd                       0\n",
       "ADX                               0\n",
       "Chaikin                           0\n",
       "OBV                               0\n",
       "ADI                               0\n",
       "CCI                               0\n",
       "ROC                               0\n",
       "MFI                               0\n",
       "WILLR                             0\n",
       "SAR                               0\n",
       "TRIX                              0\n",
       "ULTOSC                            0\n",
       "AROONOSC                          0\n",
       "O-C                               0\n",
       "H-L                               0\n",
       "Log_Return                        0\n",
       "Pass_Returns_2                    0\n",
       "Pass_Returns_3                    0\n",
       "Pass_Returns_5                    0\n",
       "Momentum_2                        0\n",
       "Momentum_3                        0\n",
       "Momentum_5                        0\n",
       "SMA_2                             0\n",
       "SMA_3                             0\n",
       "SMA_5                             0\n",
       "EMA                               0\n",
       "Mkt-RF                            0\n",
       "SMB                               0\n",
       "HML                               0\n",
       "RMW                               0\n",
       "CMA                               0\n",
       "RF                                0\n",
       "Mom                               0\n",
       "Sign                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check for missing values\n",
    "df_Features.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c91be2",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797ebc0",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "731e710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "\n",
    "def vif(X):\n",
    "# perform feature scaling\n",
    "    xs = scaler.fit_transform(X)\n",
    "    # subsume into a dataframe\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Features\"] = X.columns\n",
    "    vif[\"VIF Factor\"] = [variance_inflation_factor(xs, i) for i in range(xs.shape[1])]\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8757e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# List scores\n",
    "vif_score=vif(X).round(2)\n",
    "#Drop VIF score > 5\n",
    "X_method1=X.loc[:,vif_score[vif_score[\"VIF Factor\"]<6]['Features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29cacff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7, 17, 29, 39, 41, 44, 45])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SelectKBest\n",
    "method2 = SelectKBest(f_regression, k=8)\n",
    "# selector1 = SelectPercentile(f_regression, percentile=25)\n",
    "# Fit the model\n",
    "method2.fit(X,y)\n",
    "# Show selected features\n",
    "method2.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47c0e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GoogleIndex</td>\n",
       "      <td>0.809973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.860144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HML</td>\n",
       "      <td>0.917835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pass_Returns_2</td>\n",
       "      <td>1.044601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MACD_hist</td>\n",
       "      <td>1.121281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADI</td>\n",
       "      <td>2.094412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mom</td>\n",
       "      <td>2.633107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mkt-RF</td>\n",
       "      <td>4.043138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature   F-score\n",
       "1      GoogleIndex  0.809973\n",
       "44              RF  0.860144\n",
       "41             HML  0.917835\n",
       "29  Pass_Returns_2  1.044601\n",
       "7        MACD_hist  1.121281\n",
       "17             ADI  2.094412\n",
       "45          Mom     2.633107\n",
       "39          Mkt-RF  4.043138"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate the score\n",
    "m2_feature=pd.DataFrame({'feature':X.columns,'F-score':method2.scores_}).sort_values('F-score')\n",
    "m2_feature.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1f11652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GoogleIndex</th>\n",
       "      <th>RF</th>\n",
       "      <th>HML</th>\n",
       "      <th>Pass_Returns_2</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>ADI</th>\n",
       "      <th>Mom</th>\n",
       "      <th>Mkt-RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.033872</td>\n",
       "      <td>-0.351827</td>\n",
       "      <td>3.946467e+06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.046762</td>\n",
       "      <td>-0.472709</td>\n",
       "      <td>-1.868466e+06</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.026136</td>\n",
       "      <td>-0.503842</td>\n",
       "      <td>1.139930e+06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.040998</td>\n",
       "      <td>-0.564967</td>\n",
       "      <td>-1.416376e+05</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.018865</td>\n",
       "      <td>-0.592217</td>\n",
       "      <td>3.096398e+05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.049177</td>\n",
       "      <td>-5.785360</td>\n",
       "      <td>1.287580e+08</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.051513</td>\n",
       "      <td>-4.406893</td>\n",
       "      <td>1.292290e+08</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.026702</td>\n",
       "      <td>-3.013866</td>\n",
       "      <td>1.299415e+08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>-1.268159</td>\n",
       "      <td>1.306256e+08</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.008798</td>\n",
       "      <td>-0.019902</td>\n",
       "      <td>1.296943e+08</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2766 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GoogleIndex   RF   HML  Pass_Returns_2  MACD_hist           ADI  Mom     \\\n",
       "0              12  0.0  0.77        0.033872  -0.351827  3.946467e+06   -0.01   \n",
       "1              12  0.0  0.07       -0.046762  -0.472709 -1.868466e+06   -0.58   \n",
       "2              12  0.0  0.13       -0.026136  -0.503842  1.139930e+06    0.12   \n",
       "3              12  0.0 -0.34        0.040998  -0.564967 -1.416376e+05   -0.51   \n",
       "4              12  0.0 -0.27       -0.018865  -0.592217  3.096398e+05    0.35   \n",
       "...           ...  ...   ...             ...        ...           ...     ...   \n",
       "2761           81  0.0  0.19        0.049177  -5.785360  1.287580e+08    0.58   \n",
       "2762           81  0.0 -0.36        0.051513  -4.406893  1.292290e+08    0.95   \n",
       "2763           81  0.0 -0.48       -0.026702  -3.013866  1.299415e+08    0.09   \n",
       "2764           81  0.0  0.29        0.009004  -1.268159  1.306256e+08    1.93   \n",
       "2765           81  0.0  0.81       -0.008798  -0.019902  1.296943e+08   -0.53   \n",
       "\n",
       "      Mkt-RF  \n",
       "0       1.18  \n",
       "1      -0.26  \n",
       "2       0.59  \n",
       "3      -0.15  \n",
       "4      -0.21  \n",
       "...      ...  \n",
       "2761    2.06  \n",
       "2762    0.97  \n",
       "2763    0.71  \n",
       "2764    1.22  \n",
       "2765   -0.27  \n",
       "\n",
       "[2766 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter six features with highest score\n",
    "X_method2 = X.loc[:,m2_feature.tail(8)['feature']]\n",
    "X_method2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b099c",
   "metadata": {},
   "source": [
    "Class Imbalance\n",
    "A major problem in classification that can arise depending on the data set available is class imbalance. This means, in the context of binary labels, that the frequency of one particular class compared to the other class might be higher. This might lead to situations in which the [learning algorithm] neural network simply predicts the class with the higher frequency since this already can lead to low loss and high accuracy values. By applying appropriate weights, one can make sure that both classes gain equal importance during the [ML] DNN training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49bcf262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sign\n",
       "1.0    1421\n",
       "0.0    1345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class frequency\n",
    "c =  df_Features['Sign'].value_counts()\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb35ebd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Revenue', 'Gross Profit', 'ESG Score',\n",
       "       'Environmental Pillar Score', 'Social Pillar Score',\n",
       "       'Governance Pillar Score', 'Three_Component_Index',\n",
       "       'News_Based_Policy_Uncert_Index', 'GoogleIndex', 'Adj Close', 'Volume',\n",
       "       'RSI', 'MACD', 'MACD_signal', 'MACD_hist', 'BBANDS_upper',\n",
       "       'BBANDS_middle', 'BBANDS_lower', 'ATR', 'Stoch_slowk', 'Stoch_slowd',\n",
       "       'ADX', 'Chaikin', 'OBV', 'ADI', 'CCI', 'ROC', 'MFI', 'WILLR', 'SAR',\n",
       "       'TRIX', 'ULTOSC', 'AROONOSC', 'O-C', 'H-L', 'Log_Return',\n",
       "       'Pass_Returns_2', 'Pass_Returns_3', 'Pass_Returns_5', 'Momentum_2',\n",
       "       'Momentum_3', 'Momentum_5', 'SMA_2', 'SMA_3', 'SMA_5', 'EMA', 'Mkt-RF',\n",
       "       'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Mom   ', 'Sign'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e128ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_Features.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7245f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.029368029739777, 1: 0.974313863476425}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class weight function\n",
    "def cwts(dfs):\n",
    "    c0, c1 = np.bincount(dfs['Sign'])\n",
    "    w0=(1/c0)*(len(df))/2 \n",
    "    w1=(1/c1)*(len(df))/2 \n",
    "    return {0: w0, 1: w1}\n",
    "# check class weights\n",
    "class_weight = cwts(data)\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bcac841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1384.5, 1384.5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the calculated weights, both classes gain equal weight\n",
    "class_weight[0] * c[0], class_weight[1] * c[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b125c",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab782dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Size 2212, 553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Always keep shuffle = False for financial time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# convert to array\n",
    "X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test) \n",
    "\n",
    "# Output the train and test data size\n",
    "print(f\"Train and Test Size {len(X_train)}, {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11ecd11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a34b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 1.029368029739777,\n",
       "                                     1: 0.974313863476425},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 1.029368029739777,\n",
       "                                     1: 0.974313863476425},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1.029368029739777,\n",
       "                                     1: 0.974313863476425},\n",
       "                       max_depth=5, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define random forest classifier\n",
    "forest = RandomForestClassifier(n_jobs=-1, \n",
    "                                class_weight=cwts(data), \n",
    "                                random_state=42, \n",
    "                                max_depth=5)\n",
    "\n",
    "# train the model\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f743dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score \t\t 0.4747292418772563\n"
     ]
    }
   ],
   "source": [
    "# print scores\n",
    "print(\"Accuracy Score \\t\\t\", accuracy_score(y_test, forest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ea2e9",
   "metadata": {},
   "source": [
    "## Borutapy\n",
    "Bortua algorithm is designed to take the “all-relevant” approach to feature selection. It is a wrapper built around the random forest classification algorithm which is relatively quick and can run without tuning of parameters and it gives a numerical estimate of the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70e12332",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m feat_selector \u001b[38;5;241m=\u001b[39m BorutaPy(forest, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# find all relevant features\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# takes input in array format not as dataframe\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mfeat_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# check selected features\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(feat_selector\u001b[38;5;241m.\u001b[39msupport_)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/boruta/boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/boruta/boruta_py.py:260\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# holds the decision about each feature:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# 0  - default state = tentative in original code\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# 1  - accepted in original code\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# -1 - rejected in original code\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m dec_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# counts how many times a given feature was more important than\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# the best of the shadow features\u001b[39;00m\n\u001b[1;32m    263\u001b[0m hit_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/__init__.py:313\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=0)\n",
    "\n",
    "# find all relevant features\n",
    "# takes input in array format not as dataframe\n",
    "feat_selector.fit(X_train, y_train) \n",
    "\n",
    "# check selected features\n",
    "print(feat_selector.support_)\n",
    "\n",
    "# check ranking of features\n",
    "print(feat_selector.ranking_)\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045142b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f415804",
   "metadata": {},
   "source": [
    "In stock forecasting, the datasets of different stock markets are diverse based on the perspective of machine learning models. The datasets broadly consist of two sets of data, namely intrinsic data and extrinsic data. Intrinsic data is primarily information mined from the stock data itself, including historical stock prices, financial indices and other technical analysis data. Due to the intrinsic properties of stock data, most of its intrinsic data are time series. External data can be highly variable and includes textual information, underlying data, industry knowledge graphs, etc.\n",
    "\n",
    "1. Stock prices: Stock prices most directly reflect the performance of the stock market and are both an input feature to the model and a predictive target. Stock prices are commonly used in the papers included in this research. However, based on different model designs, stock prices contain several types, including OPEN, HIGH, LOW and CLOSE data.\n",
    "\n",
    "2. Technical Analysis Indicators: Technical analysis indicators are commonly used tools in conventional stock analysis. These indicators are highly correlated with stock market performance and include practical financial indicators such as exchange rates, P/E ratios and volume.\n",
    "\n",
    "3. Macroeconomic data: Macroeconomic information reflects financial conditions. The Consumer Price Index (CPI) and Gross Domestic Product (GDP) are two commonly used indices that correlate with the stock market on which they are based, as they indicate market conditions and the nature of stock market rallies or falls.\n",
    "\n",
    "4. Underlying data: Underlying data describes the details of an economic entity and may include financial position, corporate structure and any other information published to shareholders. However, only a small proportion of the underlying data is utilised in deep learning models, with low reporting frequency and unstructured textual information being the two main limitations.\n",
    "\n",
    "5. Knowledge graphs: Companies in different industries may be intrinsically linked, for example, two companies merging into one, and supply chains may be impacted. In some recent experiments, knowledge graphs from open source can now be integrated with traditional stock data and further improve the performance of the model.\n",
    "\n",
    "Textual information: Textual information covers text from a variety of sources, including mainly news and reports as well as social media posts and user comments. As most textual information is unstructured, sentiment analysis is a common method of exploitation through deep machine learning. Information can be classified into several categories (positive, neutral or negative) for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46d1cd",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e497c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "features= df_Features.loc[:,[\n",
    "       'News_Based_Policy_Uncert_Index', 'GoogleIndex', 'Adj Close', 'Volume',\n",
    "       'O-C', 'H-L', 'Log_Return',  'Pass_Returns_2', 'Pass_Returns_3',\n",
    "       'Pass_Returns_5', 'Momentum_2', 'Momentum_3', 'Momentum_5', 'SMA_2',\n",
    "       'SMA_3', 'SMA_5', 'EMA']].values\n",
    "'''\n",
    "target= df_Features['Sign'].values\n",
    "features=df_Features.loc[:,[  'News_Based_Policy_Uncert_Index', 'GoogleIndex', 'Adj Close', 'Volume',\n",
    "       'RSI', 'MACD', 'MACD_signal', 'MACD_hist', 'BBANDS_upper',\n",
    "       'BBANDS_middle', 'BBANDS_lower', 'ATR', 'Stoch_slowk', 'Stoch_slowd',\n",
    "       'ADX', 'Chaikin', 'OBV', 'ADI', 'CCI', 'ROC', 'MFI', 'WILLR', 'SAR',\n",
    "       'TRIX', 'ULTOSC', 'AROONOSC', 'O-C', 'H-L', 'Log_Return',\n",
    "       'Pass_Returns_2', 'Pass_Returns_3', 'Pass_Returns_5', 'Momentum_2',\n",
    "       'Momentum_3', 'Momentum_5', 'SMA_2', 'SMA_3', 'SMA_5', 'EMA', 'Mkt-RF',\n",
    "       'SMB', 'HML', 'RMW', 'CMA', 'RF', 'Mom   ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb487693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Environmental Pillar Score</th>\n",
       "      <th>RF</th>\n",
       "      <th>HML</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>Pass_Returns_2</th>\n",
       "      <th>ADI</th>\n",
       "      <th>Mom</th>\n",
       "      <th>Mkt-RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.959752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.351827</td>\n",
       "      <td>0.033872</td>\n",
       "      <td>3.946467e+06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.959752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.472709</td>\n",
       "      <td>-0.046762</td>\n",
       "      <td>-1.868466e+06</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.959752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.503842</td>\n",
       "      <td>-0.026136</td>\n",
       "      <td>1.139930e+06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.959752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.564967</td>\n",
       "      <td>0.040998</td>\n",
       "      <td>-1.416376e+05</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.959752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.592217</td>\n",
       "      <td>-0.018865</td>\n",
       "      <td>3.096398e+05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>69.54404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.013866</td>\n",
       "      <td>-0.026702</td>\n",
       "      <td>1.299415e+08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>69.54404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.268159</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>1.306256e+08</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>69.54404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.019902</td>\n",
       "      <td>-0.008798</td>\n",
       "      <td>1.296943e+08</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>69.54404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.953918</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>1.294467e+08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>69.54404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1.495735</td>\n",
       "      <td>-0.004079</td>\n",
       "      <td>1.285618e+08</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Environmental Pillar Score   RF   HML  MACD_hist  Pass_Returns_2  \\\n",
       "0                       5.959752  0.0  0.77  -0.351827        0.033872   \n",
       "1                       5.959752  0.0  0.07  -0.472709       -0.046762   \n",
       "2                       5.959752  0.0  0.13  -0.503842       -0.026136   \n",
       "3                       5.959752  0.0 -0.34  -0.564967        0.040998   \n",
       "4                       5.959752  0.0 -0.27  -0.592217       -0.018865   \n",
       "...                          ...  ...   ...        ...             ...   \n",
       "2763                    69.54404  0.0 -0.48  -3.013866       -0.026702   \n",
       "2764                    69.54404  0.0  0.29  -1.268159        0.009004   \n",
       "2765                    69.54404  0.0  0.81  -0.019902       -0.008798   \n",
       "2766                    69.54404  0.0  0.17   0.953918       -0.020877   \n",
       "2767                    69.54404  0.0 -0.40   1.495735       -0.004079   \n",
       "\n",
       "               ADI  Mom     Mkt-RF  \n",
       "0     3.946467e+06   -0.01    1.18  \n",
       "1    -1.868466e+06   -0.58   -0.26  \n",
       "2     1.139930e+06    0.12    0.59  \n",
       "3    -1.416376e+05   -0.51   -0.15  \n",
       "4     3.096398e+05    0.35   -0.21  \n",
       "...            ...     ...     ...  \n",
       "2763  1.299415e+08    0.09    0.71  \n",
       "2764  1.306256e+08    1.93    1.22  \n",
       "2765  1.296943e+08   -0.53   -0.27  \n",
       "2766  1.294467e+08    0.41    0.06  \n",
       "2767  1.285618e+08   -1.05   -0.15  \n",
       "\n",
       "[2768 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=X_method2\n",
    "X_method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "838491b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 23ms/step - loss: 0.6950 - accuracy: 0.5196\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6927 - accuracy: 0.5233\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6954 - accuracy: 0.5178\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6933 - accuracy: 0.5018\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6925 - accuracy: 0.5201\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6928 - accuracy: 0.5100\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6928 - accuracy: 0.5169\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6923 - accuracy: 0.5228\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.6921 - accuracy: 0.5233\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.6924 - accuracy: 0.5201\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6945 - accuracy: 0.5055\n",
      "Accuracy: 0.5054744482040405\n"
     ]
    }
   ],
   "source": [
    "# Normalize the feature data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Create rolling windows of size window_size\n",
    "window_size = 30\n",
    "X = []\n",
    "y = []\n",
    "for i in range(window_size, len(scaled_features)):\n",
    "    X.append(scaled_features[i-window_size:i])\n",
    "    y.append(target[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa47d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8343b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90599475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaledtrain = scaler.fit_transform(X_train)\n",
    "scaledtest = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b652120b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time_series_generator import TimeseriesGenerator\n",
    "\n",
    "# sequence length\n",
    "seqlen = 21\n",
    "\n",
    "# number of features\n",
    "numfeat = X.shape[1]\n",
    "# generate train and test sequence data\n",
    "g = TimeseriesGenerator(scaledtrain, y_train, length=seqlen)\n",
    "g_ = TimeseriesGenerator(scaledtest, y_test, length=seqlen)\n",
    "# verify length\n",
    "len(g), len(g_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8a0a3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.84714830e-01, 0.00000000e+00, 1.35844992e-02, ...,\n",
       "         4.36532508e-01, 0.00000000e+00, 5.13440860e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 7.33503502e-04, ...,\n",
       "         3.96284830e-01, 0.00000000e+00, 4.36827957e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 4.51838426e-03, ...,\n",
       "         4.02476780e-01, 0.00000000e+00, 5.30913978e-01],\n",
       "        ...,\n",
       "        [1.84714830e-01, 0.00000000e+00, 4.87047400e-03, ...,\n",
       "         2.66253870e-01, 0.00000000e+00, 4.91935484e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 5.07585408e-03, ...,\n",
       "         4.08668731e-01, 0.00000000e+00, 5.95430108e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.83375876e-02, ...,\n",
       "         4.39628483e-01, 9.09090909e-02, 5.83333333e-01]],\n",
       "\n",
       "       [[1.84714830e-01, 0.00000000e+00, 7.33503502e-04, ...,\n",
       "         3.96284830e-01, 0.00000000e+00, 4.36827957e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 4.51838426e-03, ...,\n",
       "         4.02476780e-01, 0.00000000e+00, 5.30913978e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.17363247e-04, ...,\n",
       "         3.62229102e-01, 0.00000000e+00, 4.46236559e-01],\n",
       "        ...,\n",
       "        [1.84714830e-01, 0.00000000e+00, 5.07585408e-03, ...,\n",
       "         4.08668731e-01, 0.00000000e+00, 5.95430108e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.83375876e-02, ...,\n",
       "         4.39628483e-01, 9.09090909e-02, 5.83333333e-01],\n",
       "        [4.08448931e-01, 1.80327869e-01, 1.45527292e-02, ...,\n",
       "         3.71517028e-01, 9.09090909e-02, 5.14784946e-01]],\n",
       "\n",
       "       [[1.84714830e-01, 0.00000000e+00, 4.51838426e-03, ...,\n",
       "         4.02476780e-01, 0.00000000e+00, 5.30913978e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.17363247e-04, ...,\n",
       "         3.62229102e-01, 0.00000000e+00, 4.46236559e-01],\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.46709654e-04, ...,\n",
       "         3.37461300e-01, 0.00000000e+00, 5.61827957e-01],\n",
       "        ...,\n",
       "        [1.84714830e-01, 0.00000000e+00, 1.83375876e-02, ...,\n",
       "         4.39628483e-01, 9.09090909e-02, 5.83333333e-01],\n",
       "        [4.08448931e-01, 1.80327869e-01, 1.45527292e-02, ...,\n",
       "         3.71517028e-01, 9.09090909e-02, 5.14784946e-01],\n",
       "        [4.08448931e-01, 1.80327869e-01, 1.48461261e-02, ...,\n",
       "         4.70588235e-01, 9.09090909e-02, 5.25537634e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.34189937e-01, 5.57377049e-01, 9.48889437e-01, ...,\n",
       "         3.49845201e-01, 8.18181818e-01, 4.20698925e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.40204780e-01, ...,\n",
       "         3.99380805e-01, 8.18181818e-01, 2.64784946e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.50591215e-01, ...,\n",
       "         2.75541796e-01, 8.18181818e-01, 8.33333333e-01],\n",
       "        ...,\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.31168056e-01, ...,\n",
       "         3.34365325e-01, 6.36363636e-01, 5.79301075e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.66200191e-01, ...,\n",
       "         3.56037152e-01, 6.36363636e-01, 4.63709677e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.86679551e-01, ...,\n",
       "         4.76780186e-01, 6.36363636e-01, 3.58870968e-01]],\n",
       "\n",
       "       [[4.34189937e-01, 5.57377049e-01, 9.40204780e-01, ...,\n",
       "         3.99380805e-01, 8.18181818e-01, 2.64784946e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.50591215e-01, ...,\n",
       "         2.75541796e-01, 8.18181818e-01, 8.33333333e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.49945728e-01, ...,\n",
       "         3.96284830e-01, 8.18181818e-01, 6.50537634e-01],\n",
       "        ...,\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.66200191e-01, ...,\n",
       "         3.56037152e-01, 6.36363636e-01, 4.63709677e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.86679551e-01, ...,\n",
       "         4.76780186e-01, 6.36363636e-01, 3.58870968e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.95012140e-01, ...,\n",
       "         3.59133127e-01, 6.36363636e-01, 5.37634409e-01]],\n",
       "\n",
       "       [[4.34189937e-01, 5.57377049e-01, 9.50591215e-01, ...,\n",
       "         2.75541796e-01, 8.18181818e-01, 8.33333333e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.49945728e-01, ...,\n",
       "         3.96284830e-01, 8.18181818e-01, 6.50537634e-01],\n",
       "        [4.34189937e-01, 5.57377049e-01, 9.39676679e-01, ...,\n",
       "         3.18885449e-01, 8.18181818e-01, 5.91397849e-01],\n",
       "        ...,\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.86679551e-01, ...,\n",
       "         4.76780186e-01, 6.36363636e-01, 3.58870968e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 9.95012140e-01, ...,\n",
       "         3.59133127e-01, 6.36363636e-01, 5.37634409e-01],\n",
       "        [4.83990258e-01, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "         1.73374613e-01, 6.36363636e-01, 4.79838710e-01]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature set\n",
    "g[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fbb3dd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check target \n",
    "g[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d97f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2191, 21, 46) (2191,)\n"
     ]
    }
   ],
   "source": [
    "# verify batch size\n",
    "for i in range(len(g)):\n",
    "    a, b = g[i]\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f44eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "def create_model(hu=256, lookback=60, features=1):\n",
    "    \n",
    "    tf.keras.backend.clear_session()   \n",
    "\n",
    "    # instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation = 'elu', return_sequences=True, name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Drouput1'))\n",
    "    \n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=True, name='LSTM2'))\n",
    "    model.add(Dropout(0.4, name='Drouput2'))\n",
    "    \n",
    "    model.add(LSTM(units=hu, activation = 'elu', return_sequences=False, name='LSTM3'))\n",
    "    \n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))             \n",
    "    \n",
    "    # specify optimizer separately (preferred method))\n",
    "    opt = Adam(lr=0.001, epsilon=1e-08, decay=0.0)       \n",
    "    \n",
    "    # model compilation - 'binary_crossentropy' - 'accuracy' - BinaryAccuracy(name='accuracy', threshold=0.5)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e210ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.losses.BinaryCrossentropy at 0x7fbc503bc700>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1a9de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm network\n",
    "model = create_model(hu=10, lookback=seqlen, features=numfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8fb27098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (LSTM)                (None, 21, 20)            5360      \n",
      "                                                                 \n",
      " Drouput1 (Dropout)          (None, 21, 20)            0         \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 21, 10)            1240      \n",
      "                                                                 \n",
      " Drouput2 (Dropout)          (None, 21, 10)            0         \n",
      "                                                                 \n",
      " LSTM3 (LSTM)                (None, 10)                840       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,451\n",
      "Trainable params: 7,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ebe59633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# plot layers\n",
    "plot_model(model, to_file='./img/model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567f723",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da58bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'lstm_time_series')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d9baea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<time_series_generator.time_series_generator.TimeseriesGenerator at 0x7fbc60a09430>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "643d9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# Specify callback functions\n",
    "model_path = (results_path / 'model.h5').as_posix()\n",
    "logdir = os.path.join(\"./tensorboard/logs\", dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=20, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "10a9a1e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model fitting\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/data_adapter.py:1622\u001b[0m, in \u001b[0;36m_make_class_weight_map_fn.<locals>._class_weights_map_fn\u001b[0;34m(*data)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(y):\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`class_weight` is only supported for Models with a single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1620\u001b[0m     )\n\u001b[0;32m-> 1622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1624\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`class_weight` not supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3+ dimensional targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1625\u001b[0m     )\n\u001b[1;32m   1627\u001b[0m y_classes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m   1628\u001b[0m     y\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mshape(y)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: backend\u001b[38;5;241m.\u001b[39margmax(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mcast(backend\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), tf\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m   1631\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "model.fit(X_train,\n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          callbacks=my_callbacks, \n",
    "          shuffle=False,\n",
    "          class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04422952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot layers\n",
    "plot_model(model, to_file='./img/model.png', show_shapes=True, show_layer_names=True)\n",
    "Train the Model\n",
    "# Specify callback functions\n",
    "model_path = (results_path / 'model.h5').as_posix()\n",
    "logdir = os.path.join(\"./tensorboard/logs\", dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=20, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "]\n",
    "# Model fitting\n",
    "model.fit(g,\n",
    "          epochs=500, \n",
    "          verbose=1, \n",
    "          callbacks=my_callbacks, \n",
    "          shuffle=False,\n",
    "          class_weight=class_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
